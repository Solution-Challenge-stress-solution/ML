{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prislewarz/ML/blob/main/SentimentAnalysis2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnjm7BtGOPfN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel(\"emotion_corpus.xls\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[[\"감정_대분류\",\"사람문장1\"]]\n",
        "df.dropna(inplace = True)\n",
        "df"
      ],
      "metadata": {
        "id": "s4nmrzIXORso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install konlpy\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "df['사람문장1'] = df['사람문장1'].map(lambda x: ' '.join(okt.morphs(x, stem = True)))"
      ],
      "metadata": {
        "id": "s7lTIAXFOR33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[(df[\"감정_대분류\"] == \"분노\"),\"감정_대분류\"] = 0\n",
        "df.loc[(df[\"감정_대분류\"] == \"기쁨\"),\"감정_대분류\"] = 1\n",
        "df.loc[(df[\"감정_대분류\"] == \"불안\"),\"감정_대분류\"] = 2\n",
        "df.loc[(df[\"감정_대분류\"] == \"당황\"),\"감정_대분류\"] = 3\n",
        "df.loc[(df[\"감정_대분류\"] == \"슬픔\"),\"감정_대분류\"] = 4\n",
        "df.loc[(df[\"감정_대분류\"] == \"상처\"),\"감정_대분류\"] = 5\n",
        "df.columns=[\"label\",\"document\"]\n",
        "df\n",
        "# df[\"감정_대분류\"].unique()"
      ],
      "metadata": {
        "id": "Judn1CAXOR6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "train_texts = train_df['document'].astype(str).tolist() # 문자열 데이터로 명시 후 리스트 화\n",
        "train_labels = train_df['label'].tolist()\n",
        "test_texts = test_df['document'].astype(str).tolist()\n",
        "test_labels = test_df['label'].tolist()"
      ],
      "metadata": {
        "id": "fRv3Gr2tOR9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_df), len(test_df))"
      ],
      "metadata": {
        "id": "vtA71qjeOYI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "model_name = 'monologg/kobert'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "mJbQ3fjLOYLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = CustomDataset(train_encodings, train_labels)\n",
        "test_dataset = CustomDataset(test_encodings, test_labels)\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "8QrNfgklOYOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained('monologg/kobert', num_labels=6)"
      ],
      "metadata": {
        "id": "KrxRS7M-OYQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_epochs = 5\n",
        "learning_rate = 4e-5\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in tqdm(train_loader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Average Loss: {average_loss:.4f}\")"
      ],
      "metadata": {
        "id": "Omk0XlVaOeAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
        "\n",
        "        correct_predictions += torch.sum(predicted_labels == labels).item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "dJk9Pu8yOeCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = '진짜진짜 행복하다 너무 좋아'\n",
        "input_encoding = tokenizer.encode_plus(\n",
        "    input_text,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids = input_encoding['input_ids'].to(device)\n",
        "attention_mask = input_encoding['attention_mask'].to(device)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
        "predicted_labels = predicted_labels.item()\n",
        "\n",
        "print(predicted_labels)"
      ],
      "metadata": {
        "id": "iPXfJUI6OeFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"분노\" = 0\n",
        "# \"기쁨\" = 1\n",
        "# \"불안\" = 2\n",
        "# \"슬픔\" = 4\n",
        "# \"상처\" = 5"
      ],
      "metadata": {
        "id": "dJFlXh93OhDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter(df.iloc[:41304,0])"
      ],
      "metadata": {
        "id": "TjV-P977OkJ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}